{
  if (Integer.toString(taskNumber + 1).length() > 6) {
    throw new IOException("Task id too large.");
  }
  this.taskNumber=taskNumber + 1;
  this.configuration.set("mapreduce.output.basename","tmp");
  TaskAttemptID taskAttemptID=TaskAttemptID.forName("attempt__0000_r_" + String.format("%" + (6 - Integer.toString(taskNumber + 1).length()) + "s"," ").replace(" ","0") + Integer.toString(taskNumber + 1)+ "_0");
  this.configuration.set("mapred.task.id",taskAttemptID.toString());
  this.configuration.setInt("mapred.task.partition",taskNumber + 1);
  this.configuration.set("mapreduce.task.attempt.id",taskAttemptID.toString());
  this.configuration.setInt("mapreduce.task.partition",taskNumber + 1);
  try {
    this.context=HadoopUtils.instantiateTaskAttemptContext(this.configuration,taskAttemptID);
  }
 catch (  Exception e) {
    throw new RuntimeException(e);
  }
  this.fileOutputCommitter=new FileOutputCommitter(new Path(this.configuration.get("mapred.output.dir")),context);
  try {
    this.fileOutputCommitter.setupJob(HadoopUtils.instantiateJobContext(this.configuration,new JobID()));
  }
 catch (  Exception e) {
    throw new RuntimeException(e);
  }
  this.configuration.set("mapreduce.task.output.dir",this.fileOutputCommitter.getWorkPath().toString());
  try {
    this.recordWriter=this.mapreduceOutputFormat.getRecordWriter(this.context);
  }
 catch (  InterruptedException e) {
    throw new IOException("Could not create RecordWriter.",e);
  }
}
