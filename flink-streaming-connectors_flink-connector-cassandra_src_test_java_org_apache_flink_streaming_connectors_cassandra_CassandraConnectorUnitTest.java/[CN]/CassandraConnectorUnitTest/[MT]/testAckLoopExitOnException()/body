{
  final AtomicReference<Runnable> callback=new AtomicReference<>();
  final ClusterBuilder clusterBuilder=new ClusterBuilder(){
    @Override protected Cluster buildCluster(    Cluster.Builder builder){
      try {
        BoundStatement boundStatement=mock(BoundStatement.class);
        when(boundStatement.setDefaultTimestamp(any(long.class))).thenReturn(boundStatement);
        PreparedStatement preparedStatement=mock(PreparedStatement.class);
        when(preparedStatement.bind(Matchers.anyVararg())).thenReturn(boundStatement);
        ResultSetFuture future=mock(ResultSetFuture.class);
        when(future.get()).thenThrow(new RuntimeException("Expected exception."));
        doAnswer(new Answer<Void>(){
          @Override public Void answer(          InvocationOnMock invocationOnMock) throws Throwable {
            callback.set((((Runnable)invocationOnMock.getArguments()[0])));
            return null;
          }
        }
).when(future).addListener(any(Runnable.class),any(Executor.class));
        Session session=mock(Session.class);
        when(session.prepare(anyString())).thenReturn(preparedStatement);
        when(session.executeAsync(any(BoundStatement.class))).thenReturn(future);
        Cluster cluster=mock(Cluster.class);
        when(cluster.connect()).thenReturn(session);
        return cluster;
      }
 catch (      Exception e) {
        throw new RuntimeException(e);
      }
    }
  }
;
  final IterableIterator<Tuple0> iter=new IterableIterator<Tuple0>(){
    private boolean exhausted=false;
    @Override public boolean hasNext(){
      return !exhausted;
    }
    @Override public Tuple0 next(){
      exhausted=true;
      return new Tuple0();
    }
    @Override public void remove(){
    }
    @Override public Iterator<Tuple0> iterator(){
      return this;
    }
  }
;
  final AtomicReference<Boolean> exceptionCaught=new AtomicReference<>();
  Thread t=new Thread(){
    public void run(){
      try {
        CheckpointCommitter cc=mock(CheckpointCommitter.class);
        final CassandraTupleWriteAheadSink<Tuple0> sink=new CassandraTupleWriteAheadSink<>("abc",TupleTypeInfo.of(Tuple0.class).createSerializer(new ExecutionConfig()),clusterBuilder,cc);
        OneInputStreamOperatorTestHarness<Tuple0,Tuple0> harness=new OneInputStreamOperatorTestHarness(sink);
        harness.getEnvironment().getTaskConfiguration().setBoolean("checkpointing",true);
        harness.setup();
        sink.open();
        boolean result=sink.sendValues(iter,0L);
        sink.close();
        exceptionCaught.set(result == false);
      }
 catch (      Exception e) {
        throw new RuntimeException(e);
      }
    }
  }
;
  t.start();
  int count=0;
  while (t.getState() != Thread.State.WAITING && count < 100) {
    Thread.sleep(100);
    count++;
  }
  callback.get().run();
  t.join();
  Assert.assertTrue(exceptionCaught.get());
}
