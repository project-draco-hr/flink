{
  final KafkaConsumer<byte[],byte[]> consumer;
  try {
    consumer=new KafkaConsumer<>(kafkaProperties);
  }
 catch (  Throwable t) {
    running=false;
    errorHandler.reportError(t);
    return;
  }
  try {
    consumer.assign(convertKafkaPartitions(subscribedPartitions()));
    if (useMetrics) {
      final MetricGroup kafkaMetricGroup=runtimeContext.getMetricGroup().addGroup("KafkaConsumer");
      addOffsetStateGauge(kafkaMetricGroup);
      Map<MetricName,? extends Metric> metrics=consumer.metrics();
      if (metrics == null) {
        LOG.info("Consumer implementation does not support metrics");
      }
 else {
        for (        Map.Entry<MetricName,? extends Metric> metric : metrics.entrySet()) {
          kafkaMetricGroup.gauge(metric.getKey().name(),new KafkaMetricWrapper(metric.getValue()));
        }
      }
    }
    for (    KafkaTopicPartitionState<TopicPartition> partition : subscribedPartitions()) {
      if (partition.isOffsetDefined()) {
        consumer.seek(partition.getKafkaPartitionHandle(),partition.getOffset() + 1);
      }
    }
    this.consumer=consumer;
    while (running) {
      final ConsumerRecords<byte[],byte[]> records;
synchronized (consumerLock) {
        try {
          records=consumer.poll(pollTimeout);
        }
 catch (        WakeupException we) {
          if (running) {
            throw we;
          }
 else {
            continue;
          }
        }
      }
      for (      KafkaTopicPartitionState<TopicPartition> partition : subscribedPartitions()) {
        List<ConsumerRecord<byte[],byte[]>> partitionRecords=records.records(partition.getKafkaPartitionHandle());
        for (        ConsumerRecord<byte[],byte[]> record : partitionRecords) {
          T value=deserializer.deserialize(record.key(),record.value(),record.topic(),record.partition(),record.offset());
          if (deserializer.isEndOfStream(value)) {
            running=false;
            break;
          }
          emitRecord(value,partition,record.offset());
        }
      }
    }
  }
 catch (  Throwable t) {
    if (running) {
      running=false;
      errorHandler.reportError(t);
    }
 else {
      LOG.debug("Stopped ConsumerThread threw exception",t);
    }
  }
 finally {
    try {
synchronized (consumerLock) {
        consumer.close();
      }
    }
 catch (    Throwable t) {
      LOG.warn("Error while closing Kafka 0.9 consumer",t);
    }
  }
}
