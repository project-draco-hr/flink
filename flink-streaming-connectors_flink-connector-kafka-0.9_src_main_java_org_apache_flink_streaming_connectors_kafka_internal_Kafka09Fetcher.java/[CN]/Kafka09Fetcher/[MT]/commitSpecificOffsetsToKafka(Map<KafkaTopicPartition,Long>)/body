{
  KafkaTopicPartitionState<TopicPartition>[] partitions=subscribedPartitions();
  Map<TopicPartition,OffsetAndMetadata> offsetsToCommit=new HashMap<>(partitions.length);
  for (  KafkaTopicPartitionState<TopicPartition> partition : partitions) {
    Long lastProcessedOffset=offsets.get(partition.getKafkaTopicPartition());
    if (lastProcessedOffset != null) {
      long offsetToCommit=lastProcessedOffset + 1;
      offsetsToCommit.put(partition.getKafkaPartitionHandle(),new OffsetAndMetadata(offsetToCommit));
      partition.setCommittedOffset(offsetToCommit);
    }
  }
  if (nextOffsetsToCommit.getAndSet(offsetsToCommit) != null) {
    LOG.warn("Committing offsets to Kafka takes longer than the checkpoint interval. " + "Skipping commit of previous offsets because newer complete checkpoint offsets are available. " + "This does not compromise Flink's checkpoint integrity.");
  }
  if (consumer != null) {
    consumer.wakeup();
  }
}
