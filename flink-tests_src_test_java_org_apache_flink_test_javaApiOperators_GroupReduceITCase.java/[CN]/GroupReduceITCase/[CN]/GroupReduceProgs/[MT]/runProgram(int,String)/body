{
switch (progId) {
case 1:
{
      final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
      DataSet<Tuple3<Integer,Long,String>> ds=CollectionDataSets.get3TupleDataSet(env);
      DataSet<Tuple2<Integer,Long>> reduceDs=ds.groupBy(1).reduceGroup(new Tuple3GroupReduce());
      reduceDs.writeAsCsv(resultPath);
      env.execute();
      return "1,1\n" + "5,2\n" + "15,3\n"+ "34,4\n"+ "65,5\n"+ "111,6\n";
    }
case 2:
{
    final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
    DataSet<Tuple5<Integer,Long,Integer,String,Long>> ds=CollectionDataSets.get5TupleDataSet(env);
    DataSet<Tuple5<Integer,Long,Integer,String,Long>> reduceDs=ds.groupBy(4,0).reduceGroup(new Tuple5GroupReduce());
    reduceDs.writeAsCsv(resultPath);
    env.execute();
    return "1,1,0,P-),1\n" + "2,3,0,P-),1\n" + "2,2,0,P-),2\n"+ "3,9,0,P-),2\n"+ "3,6,0,P-),3\n"+ "4,17,0,P-),1\n"+ "4,17,0,P-),2\n"+ "5,11,0,P-),1\n"+ "5,29,0,P-),2\n"+ "5,25,0,P-),3\n";
  }
case 3:
{
  final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
  env.setDegreeOfParallelism(1);
  DataSet<Tuple3<Integer,Long,String>> ds=CollectionDataSets.get3TupleDataSet(env);
  DataSet<Tuple3<Integer,Long,String>> reduceDs=ds.groupBy(1).sortGroup(2,Order.ASCENDING).reduceGroup(new Tuple3SortedGroupReduce());
  reduceDs.writeAsCsv(resultPath);
  env.execute();
  return "1,1,Hi\n" + "5,2,Hello-Hello world\n" + "15,3,Hello world, how are you?-I am fine.-Luke Skywalker\n"+ "34,4,Comment#1-Comment#2-Comment#3-Comment#4\n"+ "65,5,Comment#5-Comment#6-Comment#7-Comment#8-Comment#9\n"+ "111,6,Comment#10-Comment#11-Comment#12-Comment#13-Comment#14-Comment#15\n";
}
case 4:
{
final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
DataSet<Tuple3<Integer,Long,String>> ds=CollectionDataSets.get3TupleDataSet(env);
DataSet<Tuple2<Integer,Long>> reduceDs=ds.groupBy(new KeySelector<Tuple3<Integer,Long,String>,Long>(){
  private static final long serialVersionUID=1L;
  @Override public Long getKey(  Tuple3<Integer,Long,String> in){
    return in.f1;
  }
}
).reduceGroup(new Tuple3GroupReduce());
reduceDs.writeAsCsv(resultPath);
env.execute();
return "1,1\n" + "5,2\n" + "15,3\n"+ "34,4\n"+ "65,5\n"+ "111,6\n";
}
case 5:
{
final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
DataSet<CustomType> ds=CollectionDataSets.getCustomTypeDataSet(env);
DataSet<CustomType> reduceDs=ds.groupBy(new KeySelector<CustomType,Integer>(){
private static final long serialVersionUID=1L;
@Override public Integer getKey(CustomType in){
  return in.myInt;
}
}
).reduceGroup(new CustomTypeGroupReduce());
reduceDs.writeAsText(resultPath);
env.execute();
return "1,0,Hello!\n" + "2,3,Hello!\n" + "3,12,Hello!\n"+ "4,30,Hello!\n"+ "5,60,Hello!\n"+ "6,105,Hello!\n";
}
case 6:
{
final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
DataSet<Tuple3<Integer,Long,String>> ds=CollectionDataSets.get3TupleDataSet(env);
DataSet<Tuple3<Integer,Long,String>> reduceDs=ds.reduceGroup(new AllAddingTuple3GroupReduce());
reduceDs.writeAsCsv(resultPath);
env.execute();
return "231,91,Hello World\n";
}
case 7:
{
final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
DataSet<CustomType> ds=CollectionDataSets.getCustomTypeDataSet(env);
DataSet<CustomType> reduceDs=ds.reduceGroup(new AllAddingCustomTypeGroupReduce());
reduceDs.writeAsText(resultPath);
env.execute();
return "91,210,Hello!";
}
case 8:
{
final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
DataSet<Integer> intDs=CollectionDataSets.getIntegerDataSet(env);
DataSet<Tuple3<Integer,Long,String>> ds=CollectionDataSets.get3TupleDataSet(env);
DataSet<Tuple3<Integer,Long,String>> reduceDs=ds.groupBy(1).reduceGroup(new BCTuple3GroupReduce()).withBroadcastSet(intDs,"ints");
reduceDs.writeAsCsv(resultPath);
env.execute();
return "1,1,55\n" + "5,2,55\n" + "15,3,55\n"+ "34,4,55\n"+ "65,5,55\n"+ "111,6,55\n";
}
case 9:
{
final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
DataSet<Tuple3<Integer,Long,String>> ds=CollectionDataSets.get3TupleDataSet(env);
DataSet<Tuple3<Integer,Long,String>> reduceDs=ds.groupBy(1).reduceGroup(new InputReturningTuple3GroupReduce());
reduceDs.writeAsCsv(resultPath);
env.execute();
return "11,1,Hi!\n" + "21,1,Hi again!\n" + "12,2,Hi!\n"+ "22,2,Hi again!\n"+ "13,2,Hi!\n"+ "23,2,Hi again!\n";
}
case 10:
{
final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
DataSet<CustomType> ds=CollectionDataSets.getCustomTypeDataSet(env);
DataSet<CustomType> reduceDs=ds.groupBy(new KeySelector<CustomType,Integer>(){
private static final long serialVersionUID=1L;
@Override public Integer getKey(CustomType in){
return in.myInt;
}
}
).reduceGroup(new CustomTypeGroupReduceWithCombine());
reduceDs.writeAsText(resultPath);
env.execute();
return "1,0,test1\n" + "2,3,test2\n" + "3,12,test3\n"+ "4,30,test4\n"+ "5,60,test5\n"+ "6,105,test6\n";
}
case 11:
{
final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
env.setDegreeOfParallelism(2);
DataSet<Tuple3<Integer,Long,String>> ds=CollectionDataSets.get3TupleDataSet(env);
DataSet<Tuple2<Integer,String>> reduceDs=ds.groupBy(1).reduceGroup(new Tuple3GroupReduceWithCombine());
reduceDs.writeAsCsv(resultPath);
env.execute();
return "1,test1\n" + "5,test2\n" + "15,test3\n"+ "34,test4\n"+ "65,test5\n"+ "111,test6\n";
}
case 12:
{
final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
DataSet<Tuple3<Integer,Long,String>> ds=CollectionDataSets.get3TupleDataSet(env).map(new IdentityMapper<Tuple3<Integer,Long,String>>()).setParallelism(4);
Configuration cfg=new Configuration();
cfg.setString(PactCompiler.HINT_SHIP_STRATEGY,PactCompiler.HINT_SHIP_STRATEGY_REPARTITION);
DataSet<Tuple2<Integer,String>> reduceDs=ds.reduceGroup(new Tuple3AllGroupReduceWithCombine()).withParameters(cfg);
reduceDs.writeAsCsv(resultPath);
env.execute();
return "322,testtesttesttesttesttesttesttesttesttesttesttesttesttesttesttesttesttesttesttesttest\n";
}
case 13:
{
final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
env.setDegreeOfParallelism(1);
DataSet<Tuple3<Integer,Long,String>> ds=CollectionDataSets.get3TupleDataSet(env);
DataSet<Tuple3<Integer,Long,String>> reduceDs=ds.groupBy(1).sortGroup(2,Order.DESCENDING).reduceGroup(new Tuple3SortedGroupReduce());
reduceDs.writeAsCsv(resultPath);
env.execute();
return "1,1,Hi\n" + "5,2,Hello world-Hello\n" + "15,3,Luke Skywalker-I am fine.-Hello world, how are you?\n"+ "34,4,Comment#4-Comment#3-Comment#2-Comment#1\n"+ "65,5,Comment#9-Comment#8-Comment#7-Comment#6-Comment#5\n"+ "111,6,Comment#15-Comment#14-Comment#13-Comment#12-Comment#11-Comment#10\n";
}
case 14:
{
final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
DataSet<Tuple5<Integer,Long,Integer,String,Long>> ds=CollectionDataSets.get5TupleDataSet(env);
DataSet<Tuple5<Integer,Long,Integer,String,Long>> reduceDs=ds.groupBy(new KeySelector<Tuple5<Integer,Long,Integer,String,Long>,Tuple2<Integer,Long>>(){
private static final long serialVersionUID=1L;
@Override public Tuple2<Integer,Long> getKey(Tuple5<Integer,Long,Integer,String,Long> t){
return new Tuple2<Integer,Long>(t.f0,t.f4);
}
}
).reduceGroup(new Tuple5GroupReduce());
reduceDs.writeAsCsv(resultPath);
env.execute();
return "1,1,0,P-),1\n" + "2,3,0,P-),1\n" + "2,2,0,P-),2\n"+ "3,9,0,P-),2\n"+ "3,6,0,P-),3\n"+ "4,17,0,P-),1\n"+ "4,17,0,P-),2\n"+ "5,11,0,P-),1\n"+ "5,29,0,P-),2\n"+ "5,25,0,P-),3\n";
}
default :
{
throw new IllegalArgumentException("Invalid program id");
}
}
}
