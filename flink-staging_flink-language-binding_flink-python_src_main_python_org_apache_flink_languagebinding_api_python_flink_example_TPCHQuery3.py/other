import sys
from datetime import datetime
from flink.plan.Environment import get_environment
from flink.plan.Constants import INT, STRING, FLOAT, WriteMode
from flink.functions.FilterFunction import FilterFunction
from flink.functions.ReduceFunction import ReduceFunction
from flink.functions.JoinFunction import JoinFunction
if (__name__ == '__main__'):
    env = get_environment()
    if (len(sys.argv) != 5):
        sys.exit('Usage: ./bin/pyflink.sh TPCHQuery3 <lineitem path> <customer path> <order path> <output path>')
    lineitem = env.read_csv(sys.argv[1], [INT, INT, INT, INT, INT, FLOAT, FLOAT, FLOAT, STRING, STRING, STRING, STRING, STRING, STRING, STRING, STRING], '\n', '|').project(0, 5, 6, 10).filter(LineitemFilter())
    customer = env.read_csv(sys.argv[2], [INT, STRING, STRING, INT, STRING, FLOAT, STRING, STRING], '\n', '|').project(0, 6).filter(CustomerFilter())
    order = env.read_csv(sys.argv[3], [INT, INT, STRING, FLOAT, STRING, STRING, STRING, INT, STRING], '\n', '|').project(0, 1, 4, 7).filter(OrderFilter())
    customerWithOrder = customer.join(order).where(0).equal_to(1).using(CustomerOrderJoin(), [INT, FLOAT, STRING, INT])
    result = customerWithOrder.join(lineitem).where(0).equal_to(0).using(CustomerOrderLineitemJoin(), [INT, FLOAT, STRING, INT]).group_by(0, 2, 3).reduce(SumReducer())
    result.write_csv(sys.argv[4], '\n', '|', WriteMode.OVERWRITE)
    env.set_degree_of_parallelism(1)
    env.execute(local=True)
