{
  if (isConnected) {
    throw new IllegalStateException("Can not connect to the cluster again");
  }
  LOG.info("Start actor system.");
  InetAddress ownHostname=NetUtils.findConnectingAddress(jobManagerAddress,2000,400);
  actorSystem=AkkaUtils.createActorSystem(flinkConfig,new Some(new Tuple2<String,Integer>(ownHostname.getCanonicalHostName(),0)));
  LOG.info("Start application client.");
  applicationClient=actorSystem.actorOf(Props.create(ApplicationClient.class,flinkConfig),"applicationClient");
  applicationClient.tell(new Messages.LocalRegisterClient(this.jobManagerAddress),applicationClient);
  actorRunner=new Thread(new Runnable(){
    @Override public void run(){
      actorSystem.awaitTermination();
      try {
        ApplicationReport appReport=yarnClient.getApplicationReport(appId);
        LOG.info("Application " + appId + " finished with state "+ appReport.getYarnApplicationState()+ " and final state "+ appReport.getFinalApplicationStatus()+ " at "+ appReport.getFinishTime());
        if (appReport.getYarnApplicationState() == YarnApplicationState.FAILED || appReport.getYarnApplicationState() == YarnApplicationState.KILLED) {
          LOG.warn("Application failed. Diagnostics " + appReport.getDiagnostics());
          LOG.warn("If log aggregation is activated in the Hadoop cluster, we recommend to retrieve " + "the full application log using this command:\n" + "\tyarn logs -applicationId " + appReport.getApplicationId() + "\n"+ "(It sometimes takes a few seconds until the logs are aggregated)");
        }
      }
 catch (      Exception e) {
        LOG.warn("Error while getting final application report",e);
      }
    }
  }
);
  actorRunner.setDaemon(true);
  actorRunner.start();
  pollingRunner=new PollingThread(yarnClient,appId);
  pollingRunner.setDaemon(true);
  pollingRunner.start();
  Runtime.getRuntime().addShutdownHook(clientShutdownHook);
  isConnected=true;
}
