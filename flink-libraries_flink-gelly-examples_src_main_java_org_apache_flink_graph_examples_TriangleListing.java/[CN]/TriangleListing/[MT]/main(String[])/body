{
  final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
  env.getConfig().enableObjectReuse();
  ParameterTool parameters=ParameterTool.fromArgs(args);
  if (!parameters.has("directed")) {
    printUsage();
    return;
  }
  boolean directedAlgorithm=parameters.getBoolean("directed");
  DataSet tl;
switch (parameters.get("input","")) {
case "csv":
{
      String lineDelimiter=StringEscapeUtils.unescapeJava(parameters.get("input_line_delimiter",CsvOutputFormat.DEFAULT_LINE_DELIMITER));
      String fieldDelimiter=StringEscapeUtils.unescapeJava(parameters.get("input_field_delimiter",CsvOutputFormat.DEFAULT_FIELD_DELIMITER));
      Graph<LongValue,NullValue,NullValue> graph=Graph.fromCsvReader(parameters.get("input_filename"),env).ignoreCommentsEdges("#").lineDelimiterEdges(lineDelimiter).fieldDelimiterEdges(fieldDelimiter).keyType(LongValue.class);
      if (directedAlgorithm) {
        tl=graph.run(new org.apache.flink.graph.library.clustering.directed.TriangleListing<LongValue,NullValue,NullValue>());
      }
 else {
        tl=graph.run(new org.apache.flink.graph.library.clustering.undirected.TriangleListing<LongValue,NullValue,NullValue>());
      }
    }
  break;
case "rmat":
{
  int scale=parameters.getInt("scale",DEFAULT_SCALE);
  int edgeFactor=parameters.getInt("edge_factor",DEFAULT_EDGE_FACTOR);
  RandomGenerableFactory<JDKRandomGenerator> rnd=new JDKRandomGeneratorFactory();
  long vertexCount=1L << scale;
  long edgeCount=vertexCount * edgeFactor;
  Graph<LongValue,NullValue,NullValue> graph=new RMatGraph<>(env,rnd,vertexCount,edgeCount).generate();
  if (directedAlgorithm) {
    if (scale > 32) {
      tl=graph.run(new org.apache.flink.graph.asm.simple.directed.Simplify<LongValue,NullValue,NullValue>()).run(new org.apache.flink.graph.library.clustering.directed.TriangleListing<LongValue,NullValue,NullValue>());
    }
 else {
      tl=graph.run(new TranslateGraphIds<LongValue,IntValue,NullValue,NullValue>(new LongValueToIntValue())).run(new org.apache.flink.graph.asm.simple.directed.Simplify<IntValue,NullValue,NullValue>()).run(new org.apache.flink.graph.library.clustering.directed.TriangleListing<IntValue,NullValue,NullValue>());
    }
  }
 else {
    boolean clipAndFlip=parameters.getBoolean("clip_and_flip",DEFAULT_CLIP_AND_FLIP);
    graph=graph.run(new Simplify<LongValue,NullValue,NullValue>(clipAndFlip));
    if (scale > 32) {
      tl=graph.run(new org.apache.flink.graph.asm.simple.undirected.Simplify<LongValue,NullValue,NullValue>(clipAndFlip)).run(new org.apache.flink.graph.library.clustering.undirected.TriangleListing<LongValue,NullValue,NullValue>());
    }
 else {
      tl=graph.run(new TranslateGraphIds<LongValue,IntValue,NullValue,NullValue>(new LongValueToIntValue())).run(new org.apache.flink.graph.asm.simple.undirected.Simplify<IntValue,NullValue,NullValue>(clipAndFlip)).run(new org.apache.flink.graph.library.clustering.undirected.TriangleListing<IntValue,NullValue,NullValue>());
    }
  }
}
break;
default :
printUsage();
return;
}
switch (parameters.get("output","")) {
case "print":
if (directedAlgorithm) {
for (Object e : tl.collect()) {
org.apache.flink.graph.library.clustering.directed.TriangleListing.Result result=(org.apache.flink.graph.library.clustering.directed.TriangleListing.Result)e;
System.out.println(result.toVerboseString());
}
}
 else {
tl.print();
}
break;
case "hash":
System.out.println(DataSetUtils.checksumHashCode(tl));
break;
case "csv":
String filename=parameters.get("output_filename");
String lineDelimiter=StringEscapeUtils.unescapeJava(parameters.get("output_line_delimiter",CsvOutputFormat.DEFAULT_LINE_DELIMITER));
String fieldDelimiter=StringEscapeUtils.unescapeJava(parameters.get("output_field_delimiter",CsvOutputFormat.DEFAULT_FIELD_DELIMITER));
tl.writeAsCsv(filename,lineDelimiter,fieldDelimiter);
env.execute();
break;
default :
printUsage();
return;
}
JobExecutionResult result=env.getLastJobExecutionResult();
NumberFormat nf=NumberFormat.getInstance();
System.out.println("Execution runtime: " + nf.format(result.getNetRuntime()) + " ms");
}
