{
switch (progId) {
case 1:
{
      final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
      DataSet<Tuple2<String,Integer>> input=env.readCsvFile(inReducePath).types(String.class,Integer.class).setParallelism(1);
      DataSet<Tuple2<String,Integer>> result=input.groupBy(0).reduce(new ReduceFunction<Tuple2<String,Integer>>(){
        @Override public Tuple2<String,Integer> reduce(        Tuple2<String,Integer> value1,        Tuple2<String,Integer> value2) throws Exception {
          value2.f1+=value1.f1;
          return value2;
        }
      }
);
      result.writeAsCsv(resultPath);
      env.execute();
      return "a,60\n";
    }
case 2:
{
    final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
    DataSet<Tuple2<String,Integer>> input=env.readCsvFile(inReducePath).types(String.class,Integer.class).setParallelism(1);
    DataSet<Tuple2<String,Integer>> result=input.reduce(new ReduceFunction<Tuple2<String,Integer>>(){
      @Override public Tuple2<String,Integer> reduce(      Tuple2<String,Integer> value1,      Tuple2<String,Integer> value2) throws Exception {
        if (value1.f1 % 2 == 0) {
          value1.f1+=value2.f1;
          return value1;
        }
 else {
          value2.f1+=value1.f1;
          return value2;
        }
      }
    }
);
    result.writeAsCsv(resultPath);
    env.execute();
    return "a,60\n";
  }
case 3:
{
  final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
  DataSet<Tuple2<String,Integer>> input=env.readCsvFile(inGroupReducePath).types(String.class,Integer.class).setParallelism(1);
  DataSet<Tuple2<String,Integer>> result=input.reduceGroup(new GroupReduceFunction<Tuple2<String,Integer>,Tuple2<String,Integer>>(){
    @Override public void reduce(    Iterable<Tuple2<String,Integer>> values,    Collector<Tuple2<String,Integer>> out) throws Exception {
      List<Tuple2<String,Integer>> list=new ArrayList<Tuple2<String,Integer>>();
      for (      Tuple2<String,Integer> val : values) {
        list.add(val);
      }
      for (      Tuple2<String,Integer> val : list) {
        out.collect(val);
      }
    }
  }
);
  result.writeAsCsv(resultPath);
  env.execute();
  if (env.getConfig().isObjectReuseEnabled()) {
    return "a,5\n" + "a,4\n" + "a,5\n"+ "a,4\n"+ "a,5\n";
  }
 else {
    return "a,1\n" + "a,2\n" + "a,3\n"+ "a,4\n"+ "a,5\n";
  }
}
case 4:
{
final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
DataSet<Tuple2<String,Integer>> input=env.readCsvFile(inGroupReducePath).types(String.class,Integer.class).setParallelism(1);
DataSet<Tuple2<String,Integer>> result=input.reduceGroup(new GroupReduceFunction<Tuple2<String,Integer>,Tuple2<String,Integer>>(){
  @Override public void reduce(  Iterable<Tuple2<String,Integer>> values,  Collector<Tuple2<String,Integer>> out) throws Exception {
    List<Tuple2<String,Integer>> list=new ArrayList<Tuple2<String,Integer>>();
    for (    Tuple2<String,Integer> val : values) {
      list.add(val.copy());
    }
    for (    Tuple2<String,Integer> val : list) {
      out.collect(val);
    }
  }
}
);
result.writeAsCsv(resultPath);
env.execute();
return "a,1\n" + "a,2\n" + "a,3\n"+ "a,4\n"+ "a,5\n";
}
default :
throw new IllegalArgumentException("Invalid program id");
}
}
