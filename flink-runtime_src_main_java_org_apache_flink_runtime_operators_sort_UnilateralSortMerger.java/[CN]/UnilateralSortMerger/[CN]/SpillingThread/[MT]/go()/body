{
  final Queue<CircularElement<E>> cache=new ArrayDeque<CircularElement<E>>();
  CircularElement<E> element=null;
  boolean cacheOnly=false;
  while (isRunning()) {
    try {
      element=this.queues.spill.take();
    }
 catch (    InterruptedException iex) {
      throw new IOException("The spilling thread was interrupted.");
    }
    if (element == SPILLING_MARKER) {
      break;
    }
 else     if (element == EOF_MARKER) {
      cacheOnly=true;
      break;
    }
    cache.add(element);
  }
  if (!isRunning()) {
    return;
  }
  MutableObjectIterator<E> largeRecords=null;
  if (cacheOnly && largeRecordHandler != null && largeRecordHandler.hasData()) {
    List<MemorySegment> memoryForLargeRecordSorting=new ArrayList<MemorySegment>();
    CircularElement<E> circElement;
    while ((circElement=this.queues.empty.poll()) != null) {
      memoryForLargeRecordSorting.addAll(circElement.buffer.dispose());
    }
    if (memoryForLargeRecordSorting.isEmpty()) {
      cacheOnly=false;
      LOG.debug("Going to disk-based merge because of large records.");
    }
 else {
      LOG.debug("Sorting large records, to add them to in-memory merge.");
      largeRecords=largeRecordHandler.finishWriteAndSortKeys(memoryForLargeRecordSorting);
    }
  }
  if (cacheOnly) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Initiating in memory merge.");
    }
    List<MutableObjectIterator<E>> iterators=new ArrayList<MutableObjectIterator<E>>(cache.size() + 1);
    for (    CircularElement<E> cached : cache) {
      iterators.add(cached.buffer.getIterator());
    }
    if (largeRecords != null) {
      iterators.add(largeRecords);
    }
    if (LOG.isDebugEnabled()) {
      LOG.debug("Releasing unused sort-buffer memory.");
    }
    disposeSortBuffers(true);
    setResultIterator(iterators.isEmpty() ? EmptyMutableObjectIterator.<E>get() : iterators.size() == 1 ? iterators.get(0) : new MergeIterator<E>(iterators,this.comparator));
    return;
  }
  final FileIOChannel.Enumerator enumerator=this.ioManager.createChannelEnumerator();
  List<ChannelWithBlockCount> channelIDs=new ArrayList<ChannelWithBlockCount>();
  while (isRunning()) {
    try {
      element=takeNext(this.queues.spill,cache);
    }
 catch (    InterruptedException iex) {
      if (isRunning()) {
        LOG.error("Sorting thread was interrupted (without being shut down) while grabbing a buffer. " + "Retrying to grab buffer...");
        continue;
      }
 else {
        return;
      }
    }
    if (!isRunning()) {
      return;
    }
    if (element == EOF_MARKER) {
      break;
    }
    FileIOChannel.ID channel=enumerator.next();
    registerChannelToBeRemovedAtShudown(channel);
    final BlockChannelWriter writer=this.ioManager.createBlockChannelWriter(channel);
    registerOpenChannelToBeRemovedAtShudown(writer);
    final ChannelWriterOutputView output=new ChannelWriterOutputView(writer,this.writeMemory,this.memManager.getPageSize());
    if (LOG.isDebugEnabled()) {
      LOG.debug("Spilling buffer " + element.id + ".");
    }
    element.buffer.writeToOutput(output,largeRecordHandler);
    if (LOG.isDebugEnabled()) {
      LOG.debug("Spilled buffer " + element.id + ".");
    }
    output.close();
    unregisterOpenChannelToBeRemovedAtShudown(writer);
    if (output.getBytesWritten() > 0) {
      channelIDs.add(new ChannelWithBlockCount(channel,output.getBlockCount()));
    }
    element.buffer.reset();
    this.queues.empty.add(element);
  }
  if (LOG.isDebugEnabled()) {
    LOG.debug("Spilling done.");
    LOG.debug("Releasing sort-buffer memory.");
  }
  disposeSortBuffers(false);
  List<MemorySegment> mergeReadMemory;
  if (largeRecordHandler != null && largeRecordHandler.hasData()) {
    List<MemorySegment> longRecMem;
    if (channelIDs.isEmpty()) {
      longRecMem=this.mergeReadMemory;
      mergeReadMemory=Collections.emptyList();
    }
 else {
      int maxMergedStreams=Math.min(this.maxFanIn,channelIDs.size());
      int pagesPerStream=Math.max(MIN_NUM_WRITE_BUFFERS,Math.min(MAX_NUM_WRITE_BUFFERS,this.mergeReadMemory.size() / 2 / maxMergedStreams));
      int totalMergeReadMemory=maxMergedStreams * pagesPerStream;
      mergeReadMemory=new ArrayList<MemorySegment>(totalMergeReadMemory);
      for (int i=0; i < totalMergeReadMemory; i++) {
        mergeReadMemory.add(this.mergeReadMemory.get(i));
      }
      longRecMem=new ArrayList<MemorySegment>();
      for (int i=totalMergeReadMemory; i < this.mergeReadMemory.size(); i++) {
        longRecMem.add(this.mergeReadMemory.get(i));
      }
    }
    if (LOG.isDebugEnabled()) {
      LOG.debug("Sorting keys for large records.");
    }
    largeRecords=largeRecordHandler.finishWriteAndSortKeys(longRecMem);
  }
 else {
    mergeReadMemory=this.mergeReadMemory;
  }
  while (isRunning() && channelIDs.size() > this.maxFanIn) {
    channelIDs=mergeChannelList(channelIDs,mergeReadMemory,this.writeMemory);
  }
  this.memManager.release(this.writeMemory);
  this.writeMemory.clear();
  if (channelIDs.isEmpty()) {
    if (largeRecords == null) {
      setResultIterator(EmptyMutableObjectIterator.<E>get());
    }
 else {
      setResultIterator(largeRecords);
    }
  }
 else {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Beginning final merge.");
    }
    List<List<MemorySegment>> readBuffers=new ArrayList<List<MemorySegment>>(channelIDs.size());
    getSegmentsForReaders(readBuffers,mergeReadMemory,channelIDs.size());
    setResultIterator(getMergingIterator(channelIDs,readBuffers,new ArrayList<FileIOChannel>(channelIDs.size()),largeRecords));
  }
  if (LOG.isDebugEnabled()) {
    LOG.debug("Spilling and merging thread done.");
  }
}
