{
  final ParameterTool pt=ParameterTool.fromArgs(args);
  LOG.info("Starting exactly once test");
  Properties configProps=new Properties();
  configProps.setProperty(KinesisConfigConstants.CONFIG_AWS_CREDENTIALS_PROVIDER_BASIC_ACCESSKEYID,pt.getRequired("accessKey"));
  configProps.setProperty(KinesisConfigConstants.CONFIG_AWS_CREDENTIALS_PROVIDER_BASIC_SECRETKEY,pt.getRequired("secretKey"));
  AmazonKinesisClient client=new AmazonKinesisClient(AWSUtil.getCredentialsProvider(configProps).getCredentials());
  client.setRegion(Region.getRegion(Regions.fromName(pt.getRequired("region"))));
  final String streamName="flink-test-" + UUID.randomUUID().toString();
  client.createStream(streamName,1);
  DescribeStreamResult status=client.describeStream(streamName);
  LOG.info("status {}",status);
  while (!status.getStreamDescription().getStreamStatus().equals("ACTIVE")) {
    status=client.describeStream(streamName);
    LOG.info("Status of stream {}",status);
    Thread.sleep(1000);
  }
  final Configuration flinkConfig=new Configuration();
  flinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER,1);
  flinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS,8);
  flinkConfig.setInteger(ConfigConstants.TASK_MANAGER_MEMORY_SIZE_KEY,16);
  flinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY,"0 s");
  ForkableFlinkMiniCluster flink=new ForkableFlinkMiniCluster(flinkConfig,false);
  flink.start();
  final int flinkPort=flink.getLeaderRPCPort();
  try {
    final Tuple1<Throwable> producerException=new Tuple1<>();
    Runnable producer=new Runnable(){
      @Override public void run(){
        try {
          StreamExecutionEnvironment see=StreamExecutionEnvironment.createRemoteEnvironment("localhost",flinkPort,flinkConfig);
          see.setParallelism(2);
          DataStream<String> simpleStringStream=see.addSource(new EventsGenerator(TOTAL_EVENT_COUNT)).setParallelism(1);
          FlinkKinesisProducer<String> kinesis=new FlinkKinesisProducer<>(pt.getRequired("region"),pt.getRequired("accessKey"),pt.getRequired("secretKey"),new SimpleStringSchema());
          kinesis.setFailOnError(true);
          kinesis.setDefaultStream(streamName);
          kinesis.setDefaultPartition("0");
          simpleStringStream.addSink(kinesis);
          LOG.info("Starting producing topology");
          see.execute("Producing topology");
          LOG.info("Producing topo finished");
        }
 catch (        Exception e) {
          LOG.warn("Error while running producing topology",e);
          producerException.f0=e;
        }
      }
    }
;
    Thread producerThread=new Thread(producer);
    producerThread.start();
    final Tuple1<Throwable> consumerException=new Tuple1<>();
    Runnable consumer=new Runnable(){
      @Override public void run(){
        try {
          StreamExecutionEnvironment see=StreamExecutionEnvironment.createRemoteEnvironment("localhost",flinkPort,flinkConfig);
          see.setParallelism(2);
          see.enableCheckpointing(500);
          see.setRestartStrategy(RestartStrategies.fixedDelayRestart(1,500L));
          Properties consumerProps=new Properties();
          consumerProps.setProperty(KinesisConfigConstants.CONFIG_AWS_CREDENTIALS_PROVIDER_BASIC_ACCESSKEYID,pt.getRequired("accessKey"));
          consumerProps.setProperty(KinesisConfigConstants.CONFIG_AWS_CREDENTIALS_PROVIDER_BASIC_SECRETKEY,pt.getRequired("secretKey"));
          consumerProps.setProperty(KinesisConfigConstants.CONFIG_AWS_REGION,pt.getRequired("region"));
          consumerProps.setProperty(KinesisConfigConstants.CONFIG_STREAM_INIT_POSITION_TYPE,InitialPosition.TRIM_HORIZON.name());
          DataStream<String> consuming=see.addSource(new FlinkKinesisConsumer<>(streamName,new SimpleStringSchema(),consumerProps));
          consuming.flatMap(new RichFlatMapFunction<String,String>(){
            int count=0;
            @Override public void flatMap(            String value,            Collector<String> out) throws Exception {
              if (count++ >= 200 && getRuntimeContext().getAttemptNumber() == 0) {
                throw new RuntimeException("Artificial failure. Restart pls");
              }
              out.collect(value);
            }
          }
).flatMap(new ExactlyOnceValidatingMapper());
          LOG.info("Starting consuming topology");
          tryExecute(see,"Consuming topo");
          LOG.info("Consuming topo finished");
        }
 catch (        Exception e) {
          LOG.warn("Error while running consuming topology",e);
          consumerException.f0=e;
        }
      }
    }
;
    Thread consumerThread=new Thread(consumer);
    consumerThread.start();
    long deadline=System.currentTimeMillis() + (1000 * 2 * 60);
    while (consumerThread.isAlive() || producerThread.isAlive()) {
      Thread.sleep(1000);
      if (System.currentTimeMillis() >= deadline) {
        LOG.warn("Deadline passed");
        break;
      }
    }
    if (producerThread.isAlive()) {
      producerThread.interrupt();
    }
    if (consumerThread.isAlive()) {
      consumerThread.interrupt();
    }
    if (producerException.f0 != null) {
      throw new RuntimeException("Producer failed",producerException.f0);
    }
    if (consumerException.f0 != null) {
      throw new RuntimeException("Consumer failed",consumerException.f0);
    }
    LOG.info("+++ TEST passed! +++");
  }
  finally {
    client.deleteStream(streamName);
    client.shutdown();
    flink.stop();
  }
}
