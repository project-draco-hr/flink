{
  final int NUM_ELEMENTS=20;
  final int PARALLELISM=2;
  final String outPath=hdfsURI + "/seq-no-comp-non-rolling-out";
  StreamExecutionEnvironment env=StreamExecutionEnvironment.getExecutionEnvironment();
  env.setParallelism(PARALLELISM);
  DataStream<Tuple2<Integer,String>> source=env.addSource(new TestSourceFunction(NUM_ELEMENTS)).broadcast().filter(new OddEvenFilter());
  DataStream<Tuple2<IntWritable,Text>> mapped=source.map(new MapFunction<Tuple2<Integer,String>,Tuple2<IntWritable,Text>>(){
    private static final long serialVersionUID=1L;
    @Override public Tuple2<IntWritable,Text> map(    Tuple2<Integer,String> value) throws Exception {
      return Tuple2.of(new IntWritable(value.f0),new Text(value.f1));
    }
  }
);
  RollingSink<Tuple2<IntWritable,Text>> sink=new RollingSink<Tuple2<IntWritable,Text>>(outPath).setWriter(new SequenceFileWriter<IntWritable,Text>()).setBucketer(new NonRollingBucketer()).setPartPrefix("part").setPendingPrefix("").setPendingSuffix("");
  mapped.addSink(sink);
  env.execute("RollingSink String Write Test");
  FSDataInputStream inStream=dfs.open(new Path(outPath + "/part-0-0"));
  SequenceFile.Reader reader=new SequenceFile.Reader(inStream,1000,0,100000,new Configuration());
  IntWritable intWritable=new IntWritable();
  Text txt=new Text();
  for (int i=0; i < NUM_ELEMENTS; i+=2) {
    reader.next(intWritable,txt);
    Assert.assertEquals(i,intWritable.get());
    Assert.assertEquals("message #" + i,txt.toString());
  }
  reader.close();
  inStream.close();
  inStream=dfs.open(new Path(outPath + "/part-1-0"));
  reader=new SequenceFile.Reader(inStream,1000,0,100000,new Configuration());
  for (int i=1; i < NUM_ELEMENTS; i+=2) {
    reader.next(intWritable,txt);
    Assert.assertEquals(i,intWritable.get());
    Assert.assertEquals("message #" + i,txt.toString());
  }
  reader.close();
  inStream.close();
}
