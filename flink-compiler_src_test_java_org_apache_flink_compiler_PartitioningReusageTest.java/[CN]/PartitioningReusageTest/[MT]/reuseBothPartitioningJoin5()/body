{
  ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
  DataSet<Tuple3<Integer,Integer,Integer>> set1=env.readCsvFile(IN_FILE).types(Integer.class,Integer.class,Integer.class);
  DataSet<Tuple3<Integer,Integer,Integer>> set2=env.readCsvFile(IN_FILE).types(Integer.class,Integer.class,Integer.class);
  DataSet<Tuple3<Integer,Integer,Integer>> joined=set1.partitionByHash(2).map(new MockMapper()).withForwardedFields("2").join(set2.partitionByHash(1).map(new MockMapper()).withForwardedFields("1"),JoinOperatorBase.JoinHint.REPARTITION_HASH_FIRST).where(0,2).equalTo(2,1).with(new MockJoin());
  joined.print();
  JavaPlan plan=env.createProgramPlan();
  OptimizedPlan oPlan=compileWithStats(plan);
  SinkPlanNode sink=oPlan.getDataSinks().iterator().next();
  DualInputPlanNode join=(DualInputPlanNode)sink.getInput().getSource();
  checkValidJoinInputProperties(join);
}
