{
  ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
  DataSet<Tuple3<Integer,Integer,Integer>> set1=env.readCsvFile(IN_FILE).types(Integer.class,Integer.class,Integer.class);
  DataSet<Tuple3<Integer,Integer,Integer>> set2=env.readCsvFile(IN_FILE).types(Integer.class,Integer.class,Integer.class);
  DataSet<Tuple3<Integer,Integer,Integer>> joined=set1.partitionByHash(0).map(new MockMapper()).withForwardedFields("0").join(set2,JoinOperatorBase.JoinHint.REPARTITION_HASH_FIRST).where(0,1).equalTo(2,1).with(new MockJoin());
  joined.output(new DiscardingOutputFormat<Tuple3<Integer,Integer,Integer>>());
  JavaPlan plan=env.createProgramPlan();
  OptimizedPlan oPlan=compileWithStats(plan);
  SinkPlanNode sink=oPlan.getDataSinks().iterator().next();
  DualInputPlanNode join=(DualInputPlanNode)sink.getInput().getSource();
  checkValidJoinInputProperties(join);
}
