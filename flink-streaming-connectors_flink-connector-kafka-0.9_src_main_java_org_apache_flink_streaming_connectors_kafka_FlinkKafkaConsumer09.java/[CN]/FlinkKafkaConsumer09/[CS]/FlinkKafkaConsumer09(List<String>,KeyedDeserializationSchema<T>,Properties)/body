{
  super(deserializer);
  checkNotNull(topics,"topics");
  this.properties=checkNotNull(props,"props");
  setDeserializer(this.properties);
  try {
    if (properties.containsKey(KEY_POLL_TIMEOUT)) {
      this.pollTimeout=Long.parseLong(properties.getProperty(KEY_POLL_TIMEOUT));
    }
 else {
      this.pollTimeout=DEFAULT_POLL_TIMEOUT;
    }
  }
 catch (  Exception e) {
    throw new IllegalArgumentException("Cannot parse poll timeout for '" + KEY_POLL_TIMEOUT + '\'',e);
  }
  final List<KafkaTopicPartition> partitions=new ArrayList<>();
  try (KafkaConsumer<byte[],byte[]> consumer=new KafkaConsumer<>(this.properties)){
    for (    final String topic : topics) {
      List<PartitionInfo> partitionsForTopic=consumer.partitionsFor(topic);
      if (partitionsForTopic != null) {
        partitions.addAll(convertToFlinkKafkaTopicPartition(partitionsForTopic));
      }
    }
  }
   if (partitions.isEmpty()) {
    throw new RuntimeException("Unable to retrieve any partitions for the requested topics " + topics);
  }
  LOG.info("Got {} partitions from these topics: {}",partitions.size(),topics);
  if (LOG.isInfoEnabled()) {
    logPartitionInfo(LOG,partitions);
  }
  setSubscribedPartitions(partitions);
}
