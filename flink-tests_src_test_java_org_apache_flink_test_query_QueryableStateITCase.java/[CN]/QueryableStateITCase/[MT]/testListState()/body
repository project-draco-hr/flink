{
  final Deadline deadline=TEST_TIMEOUT.fromNow();
  final int numElements=128;
  final QueryableStateClient client=new QueryableStateClient(cluster.configuration());
  JobID jobId=null;
  try {
    StreamExecutionEnvironment env=StreamExecutionEnvironment.getExecutionEnvironment();
    env.setParallelism(NUM_SLOTS);
    env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE,1000));
    DataStream<Tuple2<Integer,Long>> source=env.addSource(new TestAscendingValueSource(numElements));
    ListStateDescriptor<Tuple2<Integer,Long>> listState=new ListStateDescriptor<>("any",source.getType());
    QueryableStateStream<Integer,Tuple2<Integer,Long>> queryableState=source.keyBy(new KeySelector<Tuple2<Integer,Long>,Integer>(){
      @Override public Integer getKey(      Tuple2<Integer,Long> value) throws Exception {
        return value.f0;
      }
    }
).asQueryableState("timon",listState);
    JobGraph jobGraph=env.getStreamGraph().getJobGraph();
    jobId=jobGraph.getJobID();
    cluster.submitJobDetached(jobGraph);
    long expected=numElements + 1;
    FiniteDuration retryDelay=new FiniteDuration(1,TimeUnit.SECONDS);
    for (int key=0; key < NUM_SLOTS; key++) {
      final byte[] serializedKey=KvStateRequestSerializer.serializeKeyAndNamespace(key,queryableState.getKeySerializer(),VoidNamespace.INSTANCE,VoidNamespaceSerializer.INSTANCE);
      boolean success=false;
      while (deadline.hasTimeLeft() && !success) {
        Future<byte[]> future=getKvStateWithRetries(client,jobId,queryableState.getQueryableStateName(),key,serializedKey,retryDelay);
        byte[] serializedValue=Await.result(future,deadline.timeLeft());
        List<Tuple2<Integer,Long>> list=KvStateRequestSerializer.deserializeList(serializedValue,queryableState.getValueSerializer());
        if (list.size() == expected) {
          for (int i=0; i < expected; i++) {
            Tuple2<Integer,Long> elem=list.get(i);
            assertEquals("Key mismatch",key,elem.f0.intValue());
            assertEquals("Value mismatch",i,elem.f1.longValue());
          }
          success=true;
        }
 else {
          Thread.sleep(50);
        }
      }
      assertTrue("Did not succeed query",success);
    }
  }
  finally {
    if (jobId != null) {
      Future<CancellationSuccess> cancellation=cluster.getLeaderGateway(deadline.timeLeft()).ask(new JobManagerMessages.CancelJob(jobId),deadline.timeLeft()).mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class));
      Await.ready(cancellation,deadline.timeLeft());
    }
    client.shutDown();
  }
}
