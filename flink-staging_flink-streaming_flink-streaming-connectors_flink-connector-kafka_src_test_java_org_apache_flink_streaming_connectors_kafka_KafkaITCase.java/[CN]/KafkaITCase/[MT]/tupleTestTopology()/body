{
  LOG.info("Starting KafkaITCase.tupleTestTopology()");
  String topic="tupleTestTopic";
  createTestTopic(topic,1,1);
  final StreamExecutionEnvironment env=StreamExecutionEnvironment.createLocalEnvironment(1);
  DataStreamSource<Tuple2<Long,String>> consuming=env.addSource(new PersistentKafkaSource<Tuple2<Long,String>>(topic,new Utils.TypeInformationSerializationSchema<Tuple2<Long,String>>(new Tuple2<Long,String>(1L,""),env.getConfig()),standardCC));
  consuming.addSink(new RichSinkFunction<Tuple2<Long,String>>(){
    private static final long serialVersionUID=1L;
    int elCnt=0;
    int start=-1;
    BitSet validator=new BitSet(101);
    @Override public void invoke(    Tuple2<Long,String> value) throws Exception {
      LOG.info("Got value " + value);
      String[] sp=value.f1.split("-");
      int v=Integer.parseInt(sp[1]);
      assertEquals(value.f0 - 1000,(long)v);
      if (start == -1) {
        start=v;
      }
      Assert.assertFalse("Received tuple twice",validator.get(v - start));
      validator.set(v - start);
      elCnt++;
      if (elCnt == 100) {
        int nc;
        if ((nc=validator.nextClearBit(0)) != 100) {
          throw new RuntimeException("The bitset was not set to 1 on all elements. Next clear:" + nc + " Set: "+ validator);
        }
        throw new SuccessException();
      }
    }
    @Override public void close() throws Exception {
      super.close();
      Assert.assertTrue("No element received",elCnt > 0);
    }
  }
);
  DataStream<Tuple2<Long,String>> stream=env.addSource(new SourceFunction<Tuple2<Long,String>>(){
    private static final long serialVersionUID=1L;
    boolean running=true;
    @Override public void run(    Object checkpointLock,    Collector<Tuple2<Long,String>> collector) throws Exception {
      LOG.info("Starting source.");
      int cnt=0;
      while (running) {
        collector.collect(new Tuple2<Long,String>(1000L + cnt,"kafka-" + cnt++));
        LOG.info("Produced " + cnt);
        try {
          Thread.sleep(100);
        }
 catch (        InterruptedException ignored) {
        }
      }
    }
    @Override public void cancel(){
      LOG.info("Source got cancel()");
      running=false;
    }
  }
);
  stream.addSink(new KafkaSink<Tuple2<Long,String>>(brokerConnectionStrings,topic,new Utils.TypeInformationSerializationSchema<Tuple2<Long,String>>(new Tuple2<Long,String>(1L,""),env.getConfig())));
  tryExecute(env,"tupletesttopology");
  LOG.info("Finished KafkaITCase.tupleTestTopology()");
}
