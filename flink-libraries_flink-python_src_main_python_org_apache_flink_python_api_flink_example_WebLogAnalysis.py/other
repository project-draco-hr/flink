import sys
from datetime import datetime
from flink.plan.Environment import get_environment
from flink.plan.Constants import INT, STRING, FLOAT, WriteMode
from flink.functions.CoGroupFunction import CoGroupFunction
from flink.functions.FilterFunction import FilterFunction
if (__name__ == '__main__'):
    env = get_environment()
    if (len(sys.argv) != 5):
        sys.exit('Usage: ./bin/pyflink.sh WebLogAnalysis <docments path> <ranks path> <visits path> <output path>')
    documents = env.read_csv(sys.argv[1], [STRING, STRING], '\n', '|').filter(DocumentFilter()).project(0)
    ranks = env.read_csv(sys.argv[2], [INT, STRING, INT], '\n', '|').filter(RankFilter())
    visits = env.read_csv(sys.argv[3], [STRING, STRING, STRING, FLOAT, STRING, STRING, STRING, STRING, INT], '\n', '|').project(1, 2).filter(VisitFilter()).project(0)
    docWithRanks = documents.join(ranks).where(0).equal_to(1).project_second(0, 1, 2)
    result = docWithRanks.co_group(visits).where(1).equal_to(0).using(AntiJoinVisits(), [INT, STRING, INT])
    result.write_csv(sys.argv[4], '\n', '|', WriteMode.OVERWRITE)
    env.set_parallelism(1)
    env.execute(local=True)
