{
  OperatorStateStore operatorStateStore=mock(OperatorStateStore.class);
  TestingListState<Tuple2<KafkaTopicPartition,Long>> expectedState=new TestingListState<>();
  expectedState.add(Tuple2.of(new KafkaTopicPartition("abc",13),16768L));
  expectedState.add(Tuple2.of(new KafkaTopicPartition("def",7),987654321L));
  TestingListState<Tuple2<KafkaTopicPartition,Long>> listState=new TestingListState<>();
  FlinkKafkaConsumerBase<String> consumer=getConsumer(null,new LinkedMap(),true);
  when(operatorStateStore.getPartitionableState(Matchers.any(ListStateDescriptor.class))).thenReturn(expectedState);
  consumer.initializeState(operatorStateStore);
  when(operatorStateStore.getPartitionableState(Matchers.any(ListStateDescriptor.class))).thenReturn(listState);
  consumer.prepareSnapshot(17L,17L);
  Set<Tuple2<KafkaTopicPartition,Long>> expected=new HashSet<Tuple2<KafkaTopicPartition,Long>>();
  for (  Tuple2<KafkaTopicPartition,Long> kafkaTopicPartitionLongTuple2 : expectedState.get()) {
    expected.add(kafkaTopicPartitionLongTuple2);
  }
  int counter=0;
  for (  Tuple2<KafkaTopicPartition,Long> kafkaTopicPartitionLongTuple2 : listState.get()) {
    assertTrue(expected.contains(kafkaTopicPartitionLongTuple2));
    counter++;
  }
  assertEquals(expected.size(),counter);
}
