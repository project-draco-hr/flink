{
  try {
    ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
    env.setDegreeOfParallelism(8);
    DataSet<Tuple2<Long,Long>> input1=env.readCsvFile("/some/file/path").types(Long.class).map(new DuplicateValue());
    DataSet<Tuple2<Long,Long>> input2=env.readCsvFile("/some/file/path").types(Long.class,Long.class);
    doBulkIteration(input1,input2).print();
    Plan p=env.createProgramPlan();
    OptimizedPlan op=compileNoStats(p);
    assertEquals(1,op.getDataSinks().size());
    assertTrue(op.getDataSinks().iterator().next().getInput().getSource() instanceof BulkIterationPlanNode);
    BulkIterationPlanNode bipn=(BulkIterationPlanNode)op.getDataSinks().iterator().next().getInput().getSource();
    for (    Channel c : bipn.getPartialSolutionPlanNode().getOutgoingChannels()) {
      assertEquals(ShipStrategyType.PARTITION_HASH,c.getShipStrategy());
    }
    new NepheleJobGraphGenerator().compileJobGraph(op);
  }
 catch (  Exception e) {
    System.err.println(e.getMessage());
    e.printStackTrace();
    fail(e.getMessage());
  }
}
