{
  env.getCheckpointConfig().setCheckpointTimeout(5000);
  final int finalCount=valuesCount * sourceParallelism;
  final TypeInformation<Tuple2<Integer,Integer>> intIntTupleType=TypeInfoParser.parse("Tuple2<Integer, Integer>");
  final TypeInformationSerializationSchema<Tuple2<Integer,Integer>> deser=new TypeInformationSerializationSchema<>(intIntTupleType,env.getConfig());
  FlinkKafkaConsumerBase<Tuple2<Integer,Integer>> consumer=kafkaServer.getConsumer(topicName,deser,cc);
  DataStream<Tuple2<Integer,Integer>> source=env.addSource(consumer).setParallelism(sourceParallelism).map(new ThrottledMapper<Tuple2<Integer,Integer>>(20)).setParallelism(sourceParallelism);
  source.flatMap(new RichFlatMapFunction<Tuple2<Integer,Integer>,Integer>(){
    private int[] values=new int[valuesCount];
    private int count=0;
    @Override public void flatMap(    Tuple2<Integer,Integer> value,    Collector<Integer> out) throws Exception {
      values[value.f1 - startFrom]++;
      count++;
      LOG.info("Received message {}, total {} messages",value,count);
      if (count == finalCount) {
        for (int i=0; i < values.length; i++) {
          int v=values[i];
          if (v != sourceParallelism) {
            printTopic(topicName,valuesCount,deser);
            throw new RuntimeException("Expected v to be 3, but was " + v + " on element "+ i+ " array="+ Arrays.toString(values));
          }
        }
        throw new SuccessException();
      }
    }
  }
).setParallelism(1);
  tryExecute(env,"Read data from Kafka");
  LOG.info("Successfully read sequence for verification");
}
