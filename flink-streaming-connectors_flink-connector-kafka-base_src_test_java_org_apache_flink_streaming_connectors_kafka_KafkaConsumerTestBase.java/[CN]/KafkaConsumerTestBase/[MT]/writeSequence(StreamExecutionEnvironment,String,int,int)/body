{
  LOG.info("\n===================================\n== Writing sequence of " + numElements + " into "+ topicName+ " with p="+ parallelism+ "\n===================================");
  TypeInformation<Tuple2<Integer,Integer>> resultType=TypeInfoParser.parse("Tuple2<Integer, Integer>");
  DataStream<Tuple2<Integer,Integer>> stream=env.addSource(new RichParallelSourceFunction<Tuple2<Integer,Integer>>(){
    private boolean running=true;
    @Override public void run(    SourceContext<Tuple2<Integer,Integer>> ctx) throws Exception {
      int cnt=0;
      int partition=getRuntimeContext().getIndexOfThisSubtask();
      while (running && cnt < numElements) {
        ctx.collect(new Tuple2<>(partition,cnt));
        cnt++;
      }
    }
    @Override public void cancel(){
      running=false;
    }
  }
).setParallelism(parallelism);
  stream.addSink(kafkaServer.getProducer(topicName,new KeyedSerializationSchemaWrapper<>(new TypeInformationSerializationSchema<>(resultType,env.getConfig())),FlinkKafkaProducerBase.getPropertiesFromBrokerList(brokerConnectionStrings),new Tuple2Partitioner(parallelism))).setParallelism(parallelism);
  env.execute("Write sequence");
  LOG.info("Finished writing sequence");
}
