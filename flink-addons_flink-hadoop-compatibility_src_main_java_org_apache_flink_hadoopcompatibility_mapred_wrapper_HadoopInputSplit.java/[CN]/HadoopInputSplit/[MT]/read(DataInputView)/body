{
  this.splitNumber=in.readInt();
  this.hadoopInputSplitTypeName=in.readUTF();
  if (hadoopInputSplit == null) {
    try {
      Class<? extends org.apache.hadoop.io.Writable> inputSplit=Class.forName(hadoopInputSplitTypeName).asSubclass(org.apache.hadoop.io.Writable.class);
      this.hadoopInputSplit=(org.apache.hadoop.mapred.InputSplit)WritableFactories.newInstance(inputSplit);
    }
 catch (    Exception e) {
      throw new RuntimeException("Unable to create InputSplit",e);
    }
  }
  jobConf=new JobConf();
  jobConf.readFields(in);
  if (this.hadoopInputSplit instanceof Configurable) {
    ((Configurable)this.hadoopInputSplit).setConf(this.jobConf);
  }
  this.hadoopInputSplit.readFields(in);
}
