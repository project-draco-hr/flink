{
  int numTaskManagers=2;
  int numSlotsPerTaskManager=2;
  int parallelism=numTaskManagers * numSlotsPerTaskManager;
  final Deadline deadline=new FiniteDuration(5,TimeUnit.MINUTES).fromNow();
  final int numberOfCompletedCheckpoints=10;
  final File tmpDir=CommonTestUtils.createTempDirectory();
  LOG.info("Created temporary directory: " + tmpDir + ".");
  ForkableFlinkMiniCluster flink=null;
  try {
    final Configuration config=new Configuration();
    config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER,numTaskManagers);
    config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS,numSlotsPerTaskManager);
    final File checkpointDir=new File(tmpDir,"checkpoints");
    final File savepointDir=new File(tmpDir,"savepoints");
    if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {
      fail("Test setup failed: failed to create temporary directories.");
    }
    LOG.info("Created temporary checkpoint directory: " + checkpointDir + ".");
    LOG.info("Created temporary savepoint directory: " + savepointDir + ".");
    config.setString(ConfigConstants.STATE_BACKEND,"filesystem");
    config.setString(SavepointStoreFactory.SAVEPOINT_BACKEND_KEY,"filesystem");
    config.setString(FsStateBackendFactory.CHECKPOINT_DIRECTORY_URI_CONF_KEY,checkpointDir.toURI().toString());
    config.setString(SavepointStoreFactory.SAVEPOINT_DIRECTORY_KEY,savepointDir.toURI().toString());
    LOG.info("Flink configuration: " + config + ".");
    flink=new ForkableFlinkMiniCluster(config);
    LOG.info("Starting Flink cluster.");
    flink.start();
    LOG.info("Retrieving JobManager.");
    ActorGateway jobManager=Await.result(flink.leaderGateway().future(),deadline.timeLeft());
    LOG.info("JobManager: " + jobManager + ".");
    final JobGraph jobGraph=createJobGraph(parallelism,0,1000,1000);
    final JobID jobId=jobGraph.getJobID();
    InfiniteTestSource.CheckpointCompleteLatch=new CountDownLatch(numberOfCompletedCheckpoints);
    LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.");
    flink.submitJobDetached(jobGraph);
    LOG.info("Waiting for " + numberOfCompletedCheckpoints + " checkpoint complete notifications.");
    InfiniteTestSource.CheckpointCompleteLatch.await();
    LOG.info("Received all " + numberOfCompletedCheckpoints + " checkpoint complete notifications.");
    LOG.info("Triggering a savepoint.");
    Future<Object> savepointPathFuture=jobManager.ask(new TriggerSavepoint(jobId),deadline.timeLeft());
    final String savepointPath=((TriggerSavepointSuccess)Await.result(savepointPathFuture,deadline.timeLeft())).savepointPath();
    LOG.info("Retrieved savepoint path: " + savepointPath + ".");
    LOG.info("Requesting the savepoint.");
    Future<Object> savepointFuture=jobManager.ask(new RequestSavepoint(savepointPath),deadline.timeLeft());
    Savepoint savepoint=((ResponseSavepoint)Await.result(savepointFuture,deadline.timeLeft())).savepoint();
    LOG.info("Retrieved savepoint: " + savepoint + ".");
    LOG.info("Shutting down Flink cluster.");
    flink.shutdown();
    FileUtils.deleteDirectory(checkpointDir);
    LOG.info("Restarting Flink cluster.");
    flink.start();
    jobGraph.setSavepointPath(savepointPath);
    LOG.info("Resubmitting job " + jobGraph.getJobID() + " with "+ "savepoint path "+ savepointPath+ " in detached mode.");
    try {
      flink.submitJobAndWait(jobGraph,false,deadline.timeLeft());
      fail("Did not throw expected Exception because of missing checkpoint files");
    }
 catch (    Exception ignored) {
    }
  }
  finally {
    if (flink != null) {
      flink.shutdown();
    }
    if (tmpDir != null) {
      FileUtils.deleteDirectory(tmpDir);
    }
  }
}
