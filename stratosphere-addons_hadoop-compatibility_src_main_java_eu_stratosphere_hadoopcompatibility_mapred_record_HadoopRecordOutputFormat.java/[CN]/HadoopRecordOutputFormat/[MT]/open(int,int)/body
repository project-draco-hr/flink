{
  this.fileOutputCommitterWrapper.setupJob(this.jobConf);
  if (Integer.toString(taskNumber + 1).length() <= 6) {
    this.jobConf.set("mapred.task.id","attempt__0000_r_" + String.format("%" + (6 - Integer.toString(taskNumber + 1).length()) + "s"," ").replace(" ","0") + Integer.toString(taskNumber + 1)+ "_0");
    this.jobConf.set("mapreduce.task.output.dir",this.fileOutputCommitterWrapper.getTempTaskOutputPath(this.jobConf,TaskAttemptID.forName(this.jobConf.get("mapred.task.id"))).toString());
  }
 else {
    throw new IOException("task id too large");
  }
  this.recordWriter=this.hadoopOutputFormat.getRecordWriter(null,this.jobConf,Integer.toString(taskNumber + 1),new HadoopDummyProgressable());
}
