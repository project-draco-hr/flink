{
  try {
    ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
    env.setParallelism(DEFAULT_PARALLELISM);
    DataSet<Long> source1=env.generateSequence(0,1);
    DataSet<Long> source2=env.generateSequence(0,1);
    DataSet<Long> join1=source1.join(source2).where("*").equalTo("*").with(new IdentityJoiner<Long>()).name("Join 1");
    DataSet<Long> map1=join1.map(new IdentityMapper<Long>()).name("Map 1");
    DataSet<Long> reduce1=map1.groupBy("*").reduceGroup(new IdentityGroupReducer<Long>()).name("Reduce 1");
    DataSet<Long> reduce2=join1.groupBy("*").reduceGroup(new IdentityGroupReducer<Long>()).name("Reduce 2");
    DataSet<Long> map2=join1.map(new IdentityMapper<Long>()).name("Map 2");
    DataSet<Long> map3=map2.map(new IdentityMapper<Long>()).name("Map 3");
    DataSet<Long> join2=reduce1.union(reduce2).union(map2).union(map3).join(map2,JoinHint.REPARTITION_SORT_MERGE).where("*").equalTo("*").with(new IdentityJoiner<Long>()).name("Join 2");
    join2.output(new DiscardingOutputFormat<Long>());
    Plan plan=env.createProgramPlan();
    OptimizedPlan oPlan=compileNoStats(plan);
    JobGraphGenerator jobGen=new JobGraphGenerator();
    jobGen.compileJobGraph(oPlan);
  }
 catch (  Exception e) {
    e.printStackTrace();
    Assert.fail(e.getMessage());
  }
}
