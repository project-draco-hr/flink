{
  super.open(parameters);
  final int numConsumers=getRuntimeContext().getNumberOfParallelSubtasks();
  final int thisConsumerIndex=getRuntimeContext().getIndexOfThisSubtask();
  subscribedPartitions=assignPartitions(this.partitionInfos,numConsumers,thisConsumerIndex);
  if (LOG.isInfoEnabled()) {
    LOG.info("Kafka consumer {} will read partitions {} out of partitions {}",thisConsumerIndex,KafkaTopicPartitionLeader.toString(subscribedPartitions),this.partitionInfos.size());
  }
  if (subscribedPartitions.isEmpty()) {
    LOG.info("Kafka consumer {} has no partitions (empty source)",thisConsumerIndex);
    this.fetcher=null;
    return;
  }
  fetcher=new LegacyFetcher(this.subscribedPartitions,props,getRuntimeContext().getTaskName());
  offsetHandler=new ZookeeperOffsetHandler(props);
  committedOffsets=new HashMap<>();
  if (restoreToOffset != null) {
    if (LOG.isInfoEnabled()) {
      LOG.info("Consumer {} is restored from previous checkpoint: {}",thisConsumerIndex,KafkaTopicPartition.toString(restoreToOffset));
    }
    for (    Map.Entry<KafkaTopicPartition,Long> restorePartition : restoreToOffset.entrySet()) {
      fetcher.seek(restorePartition.getKey(),restorePartition.getValue() + 1);
    }
    this.offsetsState=restoreToOffset;
    restoreToOffset=null;
  }
 else {
    offsetsState=new HashMap<>();
    offsetHandler.seekFetcherToInitialOffsets(subscribedPartitions,fetcher);
  }
}
