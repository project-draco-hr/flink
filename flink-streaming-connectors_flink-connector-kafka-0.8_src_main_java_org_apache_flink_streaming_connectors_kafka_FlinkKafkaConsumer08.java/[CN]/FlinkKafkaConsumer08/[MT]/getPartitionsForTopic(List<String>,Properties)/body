{
  String seedBrokersConfString=properties.getProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG);
  final int numRetries=getIntFromConfig(properties,GET_PARTITIONS_RETRIES_KEY,DEFAULT_GET_PARTITIONS_RETRIES);
  requireNonNull(seedBrokersConfString,"Configuration property " + ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG + " not set");
  String[] seedBrokers=seedBrokersConfString.split(",");
  List<KafkaTopicPartitionLeader> partitions=new ArrayList<>();
  final String clientId="flink-kafka-consumer-partition-lookup";
  final int soTimeout=getIntFromConfig(properties,"socket.timeout.ms",30000);
  final int bufferSize=getIntFromConfig(properties,"socket.receive.buffer.bytes",65536);
  Random rnd=new Random();
  retryLoop:   for (int retry=0; retry < numRetries; retry++) {
    int index=rnd.nextInt(seedBrokers.length);
    brokersLoop:     for (int arrIdx=0; arrIdx < seedBrokers.length; arrIdx++) {
      String seedBroker=seedBrokers[index];
      LOG.info("Trying to get topic metadata from broker {} in try {}/{}",seedBroker,retry,numRetries);
      if (++index == seedBrokers.length) {
        index=0;
      }
      URL brokerUrl=NetUtils.getCorrectHostnamePort(seedBroker);
      SimpleConsumer consumer=null;
      try {
        consumer=new SimpleConsumer(brokerUrl.getHost(),brokerUrl.getPort(),soTimeout,bufferSize,clientId);
        TopicMetadataRequest req=new TopicMetadataRequest(topics);
        kafka.javaapi.TopicMetadataResponse resp=consumer.send(req);
        List<TopicMetadata> metaData=resp.topicsMetadata();
        partitions.clear();
        for (        TopicMetadata item : metaData) {
          if (item.errorCode() != ErrorMapping.NoError()) {
            LOG.warn("Error while getting metadata from broker " + seedBroker + " to find partitions "+ "for "+ topics.toString()+ ". Error: "+ ErrorMapping.exceptionFor(item.errorCode()).getMessage());
            continue brokersLoop;
          }
          if (!topics.contains(item.topic())) {
            LOG.warn("Received metadata from topic " + item.topic() + " even though it was not requested. Skipping ...");
            continue brokersLoop;
          }
          for (          PartitionMetadata part : item.partitionsMetadata()) {
            Node leader=brokerToNode(part.leader());
            KafkaTopicPartition ktp=new KafkaTopicPartition(item.topic(),part.partitionId());
            KafkaTopicPartitionLeader pInfo=new KafkaTopicPartitionLeader(ktp,leader);
            partitions.add(pInfo);
          }
        }
        break retryLoop;
      }
 catch (      Exception e) {
        LOG.warn("Error communicating with broker " + seedBroker + " to find partitions for "+ topics.toString()+ "."+ ""+ e.getClass()+ ". Message: "+ e.getMessage());
        LOG.debug("Detailed trace",e);
        try {
          Thread.sleep(500);
        }
 catch (        InterruptedException e1) {
        }
      }
 finally {
        if (consumer != null) {
          consumer.close();
        }
      }
    }
  }
  return partitions;
}
