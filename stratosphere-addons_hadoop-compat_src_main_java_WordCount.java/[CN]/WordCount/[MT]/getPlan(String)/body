{
  int numSubTasks=(args.length > 0 ? Integer.parseInt(args[0]) : 1);
  String dataInput=(args.length > 1 ? args[1] : "");
  String output=(args.length > 2 ? args[2] : "");
  HadoopDataSource source=new HadoopDataSource(new HadoopInputFormatWrapper(new org.apache.hadoop.mapred.TextInputFormat(),new JobConf()),dataInput,"Input Lines");
  MapOperator mapper=MapOperator.builder(new TokenizeLine()).input(source).name("Tokenize Lines").build();
  ReduceOperator reducer=ReduceOperator.builder(CountWords.class,StringValue.class,0).input(mapper).name("Count Words").build();
  FileDataSink out=new FileDataSink(new CsvOutputFormat(),output,reducer,"Word Counts");
  CsvOutputFormat.configureRecordFormat(out).recordDelimiter('\n').fieldDelimiter(' ').field(StringValue.class,0).field(IntValue.class,1);
  Plan plan=new Plan(out,"WordCount Example");
  plan.setDefaultParallelism(numSubTasks);
  return plan;
}
