{
  DataSet<Tuple3<K,LongValue,FloatValue>> inverseLogDegree=input.run(new VertexDegree<K,VV,EV>().setParallelism(littleParallelism)).map(new VertexInverseLogDegree<K>()).setParallelism(littleParallelism).name("Vertex score");
  DataSet<Tuple3<K,K,FloatValue>> sourceInverseLogDegree=input.getEdges().join(inverseLogDegree,JoinHint.REPARTITION_HASH_SECOND).where(0).equalTo(0).projectFirst(0,1).<Tuple3<K,K,FloatValue>>projectSecond(2).setParallelism(littleParallelism).name("Edge score");
  DataSet<Tuple4<IntValue,K,K,FloatValue>> groupSpans=sourceInverseLogDegree.groupBy(0).sortGroup(1,Order.ASCENDING).reduceGroup(new GenerateGroupSpans<K>()).setParallelism(littleParallelism).name("Generate group spans");
  DataSet<Tuple4<IntValue,K,K,FloatValue>> groups=groupSpans.rebalance().setParallelism(littleParallelism).name("Rebalance").flatMap(new GenerateGroups<K>()).setParallelism(littleParallelism).name("Generate groups");
  DataSet<Tuple3<K,K,FloatValue>> twoPaths=groups.groupBy(0,1).sortGroup(2,Order.ASCENDING).reduceGroup(new GenerateGroupPairs<K>()).name("Generate group pairs");
  GroupReduceOperator<Tuple3<K,K,FloatValue>,Result<K>> scores=twoPaths.groupBy(0,1).reduceGroup(new ComputeScores<K>(minimumScore,minimumRatio)).name("Compute scores");
  if (minimumRatio > 0.0f) {
    DataSet<Tuple2<FloatValue,LongValue>> sumOfScoresAndNumberOfNeighborPairs=inverseLogDegree.map(new ComputeScoreFromVertex<K>()).setParallelism(littleParallelism).name("Average score").sum(0).andSum(1);
    scores.withBroadcastSet(sumOfScoresAndNumberOfNeighborPairs,SUM_OF_SCORES_AND_NUMBER_OF_NEIGHBOR_PAIRS);
  }
  return scores;
}
