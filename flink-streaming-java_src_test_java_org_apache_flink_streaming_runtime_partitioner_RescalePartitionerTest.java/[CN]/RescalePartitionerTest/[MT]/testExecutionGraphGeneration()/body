{
  final StreamExecutionEnvironment env=StreamExecutionEnvironment.getExecutionEnvironment();
  env.setParallelism(4);
  DataStream<String> text=env.addSource(new ParallelSourceFunction<String>(){
    @Override public void run(    SourceContext<String> ctx) throws Exception {
    }
    @Override public void cancel(){
    }
  }
).setParallelism(2);
  DataStream<Tuple2<String,Integer>> counts=text.rescale().flatMap(new FlatMapFunction<String,Tuple2<String,Integer>>(){
    @Override public void flatMap(    String value,    Collector<Tuple2<String,Integer>> out) throws Exception {
    }
  }
);
  counts.rescale().print().setParallelism(2);
  JobGraph jobGraph=env.getStreamGraph().getJobGraph();
  final JobID jobId=new JobID();
  final String jobName="Semi-Rebalance Test Job";
  final Configuration cfg=new Configuration();
  List<JobVertex> jobVertices=jobGraph.getVerticesSortedTopologicallyFromSources();
  JobVertex sourceVertex=jobVertices.get(0);
  JobVertex mapVertex=jobVertices.get(1);
  JobVertex sinkVertex=jobVertices.get(2);
  assertEquals(2,sourceVertex.getParallelism());
  assertEquals(4,mapVertex.getParallelism());
  assertEquals(2,sinkVertex.getParallelism());
  ExecutionGraph eg=new ExecutionGraph(TestingUtils.defaultExecutionContext(),jobId,jobName,cfg,new ExecutionConfig(),AkkaUtils.getDefaultTimeout(),new NoRestartStrategy(),new ArrayList<BlobKey>(),new ArrayList<URL>(),ExecutionGraph.class.getClassLoader());
  try {
    eg.attachJobGraph(jobVertices);
  }
 catch (  JobException e) {
    e.printStackTrace();
    fail("Building ExecutionGraph failed: " + e.getMessage());
  }
  ExecutionJobVertex execSourceVertex=eg.getJobVertex(sourceVertex.getID());
  ExecutionJobVertex execMapVertex=eg.getJobVertex(mapVertex.getID());
  ExecutionJobVertex execSinkVertex=eg.getJobVertex(sinkVertex.getID());
  assertEquals(0,execSourceVertex.getInputs().size());
  assertEquals(1,execMapVertex.getInputs().size());
  assertEquals(4,execMapVertex.getParallelism());
  ExecutionVertex[] mapTaskVertices=execMapVertex.getTaskVertices();
  Map<Integer,Integer> mapInputPartitionCounts=new HashMap<>();
  for (  ExecutionVertex mapTaskVertex : mapTaskVertices) {
    assertEquals(1,mapTaskVertex.getNumberOfInputs());
    assertEquals(1,mapTaskVertex.getInputEdges(0).length);
    ExecutionEdge inputEdge=mapTaskVertex.getInputEdges(0)[0];
    assertEquals(sourceVertex.getID(),inputEdge.getSource().getProducer().getJobvertexId());
    int inputPartition=inputEdge.getSource().getPartitionNumber();
    if (!mapInputPartitionCounts.containsKey(inputPartition)) {
      mapInputPartitionCounts.put(inputPartition,1);
    }
 else {
      mapInputPartitionCounts.put(inputPartition,mapInputPartitionCounts.get(inputPartition) + 1);
    }
  }
  assertEquals(2,mapInputPartitionCounts.size());
  for (  int count : mapInputPartitionCounts.values()) {
    assertEquals(2,count);
  }
  assertEquals(1,execSinkVertex.getInputs().size());
  assertEquals(2,execSinkVertex.getParallelism());
  ExecutionVertex[] sinkTaskVertices=execSinkVertex.getTaskVertices();
  Set<Integer> mapSubpartitions=new HashSet<>();
  for (  ExecutionVertex sinkTaskVertex : sinkTaskVertices) {
    assertEquals(1,sinkTaskVertex.getNumberOfInputs());
    assertEquals(2,sinkTaskVertex.getInputEdges(0).length);
    ExecutionEdge inputEdge1=sinkTaskVertex.getInputEdges(0)[0];
    ExecutionEdge inputEdge2=sinkTaskVertex.getInputEdges(0)[1];
    assertEquals(mapVertex.getID(),inputEdge1.getSource().getProducer().getJobvertexId());
    assertEquals(mapVertex.getID(),inputEdge2.getSource().getProducer().getJobvertexId());
    int inputPartition1=inputEdge1.getSource().getPartitionNumber();
    assertFalse(mapSubpartitions.contains(inputPartition1));
    mapSubpartitions.add(inputPartition1);
    int inputPartition2=inputEdge2.getSource().getPartitionNumber();
    assertFalse(mapSubpartitions.contains(inputPartition2));
    mapSubpartitions.add(inputPartition2);
  }
  assertEquals(4,mapSubpartitions.size());
}
