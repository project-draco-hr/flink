{
  FileDataSource sourceNode=new FileDataSource(TextInputFormat.class,IN_FILE_1,"Input Lines");
  MapContract mapNode=MapContract.builder(TokenizeLine.class).input(sourceNode).name("Tokenize Lines").build();
  ReduceContract reduceNode=new ReduceContract.Builder(CountWords.class,PactString.class,0).input(mapNode).name("Count Words").build();
  FileDataSink out=new FileDataSink(RecordOutputFormat.class,OUT_FILE_1,reduceNode,"Word Counts");
  RecordOutputFormat.configureRecordFormat(out).recordDelimiter('\n').fieldDelimiter(' ').lenient(true).field(PactString.class,0).field(PactInteger.class,1);
  out.setGlobalOrder(new Ordering(0,PactString.class,Order.DESCENDING),new MockDataDistribution());
  Plan p=new Plan(out,"WordCount Example");
  p.setDefaultParallelism(defaultParallelism);
  OptimizedPlan plan=compile(p);
  SinkPlanNode sink=plan.getDataSinks().iterator().next();
  SingleInputPlanNode reducer=(SingleInputPlanNode)sink.getPredecessor();
  SingleInputPlanNode mapper=(SingleInputPlanNode)reducer.getPredecessor();
  Assert.assertEquals(ShipStrategyType.FORWARD,mapper.getInput().getShipStrategy());
  Assert.assertEquals(ShipStrategyType.PARTITION_RANGE,reducer.getInput().getShipStrategy());
  Assert.assertEquals(ShipStrategyType.FORWARD,sink.getInput().getShipStrategy());
  Channel c=reducer.getInput();
  Assert.assertEquals(LocalStrategy.COMBININGSORT,c.getLocalStrategy());
  FieldList l=new FieldList(0);
  Assert.assertEquals(l,c.getShipStrategyKeys());
  Assert.assertEquals(l,c.getLocalStrategyKeys());
  Assert.assertFalse(c.getShipStrategySortOrder()[0]);
  Assert.assertFalse(c.getLocalStrategySortOrder()[0]);
}
