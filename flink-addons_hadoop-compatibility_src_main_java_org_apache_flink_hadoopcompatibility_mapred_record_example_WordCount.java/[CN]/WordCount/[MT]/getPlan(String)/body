{
  int numSubTasks=(args.length > 0 ? Integer.parseInt(args[0]) : 1);
  String dataInput=(args.length > 1 ? args[1] : "");
  String output=(args.length > 2 ? args[2] : "");
  HadoopDataSource source=new HadoopDataSource(new TextInputFormat(),new JobConf(),"Input Lines");
  TextInputFormat.addInputPath(source.getJobConf(),new Path(dataInput));
  HadoopDataSource<LongWritable,Text> sourceHadoopType=new HadoopDataSource<LongWritable,Text>(new TextInputFormat(),new JobConf(),"Input Lines",new WritableWrapperConverter<LongWritable,Text>());
  TextInputFormat.addInputPath(source.getJobConf(),new Path(dataInput));
  MapOperator mapper=MapOperator.builder(new TokenizeLine()).input(source).name("Tokenize Lines").build();
  ReduceOperator reducer=ReduceOperator.builder(CountWords.class,StringValue.class,0).input(mapper).name("Count Words").build();
  FileDataSink out=new FileDataSink(new CsvOutputFormat(),output,reducer,"Word Counts");
  CsvOutputFormat.configureRecordFormat(out).recordDelimiter('\n').fieldDelimiter(' ').field(StringValue.class,0).field(IntValue.class,1);
  Plan plan=new Plan(out,"WordCount Example");
  plan.setDefaultParallelism(numSubTasks);
  return plan;
}
