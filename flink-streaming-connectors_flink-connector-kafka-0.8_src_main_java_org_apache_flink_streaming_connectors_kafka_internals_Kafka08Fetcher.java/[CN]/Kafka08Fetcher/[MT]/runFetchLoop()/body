{
  final Map<Node,SimpleConsumerThread<T>> brokerToThread=new HashMap<>();
  final ExceptionProxy errorHandler=new ExceptionProxy(Thread.currentThread());
  final ZookeeperOffsetHandler zookeeperOffsetHandler=new ZookeeperOffsetHandler(kafkaConfig);
  this.zookeeperOffsetHandler=zookeeperOffsetHandler;
  PeriodicOffsetCommitter periodicCommitter=null;
  try {
{
      List<KafkaTopicPartition> partitionsWithNoOffset=new ArrayList<>();
      for (      KafkaTopicPartitionState<TopicAndPartition> partition : subscribedPartitions()) {
        if (!partition.isOffsetDefined()) {
          partitionsWithNoOffset.add(partition.getKafkaTopicPartition());
        }
      }
      Map<KafkaTopicPartition,Long> zkOffsets=zookeeperOffsetHandler.getOffsets(partitionsWithNoOffset);
      for (      KafkaTopicPartitionState<TopicAndPartition> partition : subscribedPartitions()) {
        Long offset=zkOffsets.get(partition.getKafkaTopicPartition());
        if (offset != null) {
          partition.setOffset(offset);
        }
      }
    }
    if (autoCommitInterval > 0) {
      LOG.info("Starting periodic offset committer, with commit interval of {}ms",autoCommitInterval);
      periodicCommitter=new PeriodicOffsetCommitter(zookeeperOffsetHandler,subscribedPartitions(),errorHandler,autoCommitInterval);
      periodicCommitter.setName("Periodic Kafka partition offset committer");
      periodicCommitter.setDaemon(true);
      periodicCommitter.start();
    }
    if (useMetrics) {
      final MetricGroup kafkaMetricGroup=runtimeContext.getMetricGroup().addGroup("KafkaConsumer");
      addOffsetStateGauge(kafkaMetricGroup);
    }
    while (running) {
      errorHandler.checkAndThrowException();
      List<KafkaTopicPartitionState<TopicAndPartition>> partitionsToAssign=unassignedPartitionsQueue.getBatchBlocking(5000);
      partitionsToAssign.remove(MARKER);
      if (!partitionsToAssign.isEmpty()) {
        LOG.info("Assigning {} partitions to broker threads",partitionsToAssign.size());
        Map<Node,List<KafkaTopicPartitionState<TopicAndPartition>>> partitionsWithLeaders=findLeaderForPartitions(partitionsToAssign,kafkaConfig);
        for (        Map.Entry<Node,List<KafkaTopicPartitionState<TopicAndPartition>>> partitionsWithLeader : partitionsWithLeaders.entrySet()) {
          final Node leader=partitionsWithLeader.getKey();
          final List<KafkaTopicPartitionState<TopicAndPartition>> partitions=partitionsWithLeader.getValue();
          SimpleConsumerThread<T> brokerThread=brokerToThread.get(leader);
          if (!running) {
            break;
          }
          if (brokerThread == null || !brokerThread.getNewPartitionsQueue().isOpen()) {
            brokerThread=createAndStartSimpleConsumerThread(partitions,leader,errorHandler);
            brokerToThread.put(leader,brokerThread);
          }
 else {
            ClosableBlockingQueue<KafkaTopicPartitionState<TopicAndPartition>> newPartitionsQueue=brokerThread.getNewPartitionsQueue();
            for (            KafkaTopicPartitionState<TopicAndPartition> fp : partitions) {
              if (!newPartitionsQueue.addIfOpen(fp)) {
                List<KafkaTopicPartitionState<TopicAndPartition>> seedPartitions=new ArrayList<>();
                seedPartitions.add(fp);
                brokerThread=createAndStartSimpleConsumerThread(seedPartitions,leader,errorHandler);
                brokerToThread.put(leader,brokerThread);
                newPartitionsQueue=brokerThread.getNewPartitionsQueue();
              }
            }
          }
        }
      }
 else {
        Iterator<SimpleConsumerThread<T>> bttIterator=brokerToThread.values().iterator();
        while (bttIterator.hasNext()) {
          SimpleConsumerThread<T> thread=bttIterator.next();
          if (!thread.getNewPartitionsQueue().isOpen()) {
            LOG.info("Removing stopped consumer thread {}",thread.getName());
            bttIterator.remove();
          }
        }
      }
      if (brokerToThread.size() == 0 && unassignedPartitionsQueue.isEmpty()) {
        if (unassignedPartitionsQueue.close()) {
          LOG.info("All consumer threads are finished, there are no more unassigned partitions. Stopping fetcher");
          break;
        }
      }
    }
  }
 catch (  InterruptedException e) {
    errorHandler.checkAndThrowException();
    throw e;
  }
 finally {
    this.running=false;
    this.zookeeperOffsetHandler=null;
    if (periodicCommitter != null) {
      periodicCommitter.shutdown();
    }
    try {
      int runningThreads;
      do {
        runningThreads=0;
        Iterator<SimpleConsumerThread<T>> threads=brokerToThread.values().iterator();
        while (threads.hasNext()) {
          SimpleConsumerThread<?> t=threads.next();
          if (t.isAlive()) {
            t.cancel();
            runningThreads++;
          }
 else {
            threads.remove();
          }
        }
        if (runningThreads > 0) {
          for (          SimpleConsumerThread<?> t : brokerToThread.values()) {
            t.join(500 / runningThreads + 1);
          }
        }
      }
 while (runningThreads > 0);
    }
 catch (    Throwable t) {
      LOG.error("Exception while shutting down consumer threads",t);
    }
    try {
      zookeeperOffsetHandler.close();
    }
 catch (    Throwable t) {
      LOG.error("Exception while shutting down ZookeeperOffsetHandler",t);
    }
  }
}
